"{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": null, \"filters\": \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": \"<unk>\", \"document_count\": 80, \"word_counts\": \"{\\\"baum\\\": 20, \\\"essen\\\": 20, \\\"haus\\\": 20, \\\"hund\\\": 20}\", \"word_docs\": \"{\\\"baum\\\": 20, \\\"essen\\\": 20, \\\"haus\\\": 20, \\\"hund\\\": 20}\", \"index_docs\": \"{\\\"2\\\": 20, \\\"3\\\": 20, \\\"4\\\": 20, \\\"5\\\": 20}\", \"index_word\": \"{\\\"1\\\": \\\"<unk>\\\", \\\"2\\\": \\\"baum\\\", \\\"3\\\": \\\"essen\\\", \\\"4\\\": \\\"haus\\\", \\\"5\\\": \\\"hund\\\"}\", \"word_index\": \"{\\\"<unk>\\\": 1, \\\"baum\\\": 2, \\\"essen\\\": 3, \\\"haus\\\": 4, \\\"hund\\\": 5, \\\"<start>\\\": 6, \\\"<end>\\\": 7}\"}}"